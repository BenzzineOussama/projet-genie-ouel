# Guide d'utilisation des fichiers CSV avec l'interface GUI

## ðŸš€ DÃ©marrage rapide

1. **Lancer l'interface GUI** :
   ```bash
   python main_gui.py
   ```

2. **Charger un fichier CSV** :
   - Allez dans l'onglet "Training"
   - Cliquez sur le bouton "Load CSV" dans la section "Data Loading"
   - Naviguez vers le dossier `datasets/`
   - SÃ©lectionnez un des fichiers CSV crÃ©Ã©s
   - Le nombre d'Ã©chantillons chargÃ©s s'affichera sous les boutons

## ðŸ“Š Fichiers CSV disponibles

### Pour dÃ©buter (problÃ¨mes simples) :
- **linear_classification.csv** : Classification binaire linÃ©aire (2 features)
- **and_gate.csv** : Porte logique AND
- **or_gate.csv** : Porte logique OR

### ProblÃ¨mes intermÃ©diaires :
- **moons_classification.csv** : Forme de lunes (non-linÃ©aire)
- **circles_classification.csv** : Cercles concentriques
- **blobs_classification.csv** : Clusters sÃ©parÃ©s (4 classes)

### ProblÃ¨mes avancÃ©s :
- **spiral_classification.csv** : Spirale (trÃ¨s non-linÃ©aire)
- **complex_classification.csv** : 5 features, 2 classes
- **multiclass_classification.csv** : 3 features, 3 classes

### RÃ©gression :
- **regression.csv** : RÃ©gression linÃ©aire
- **sine_regression.csv** : Fonction sinus

## ðŸ”§ Configuration recommandÃ©e par type de problÃ¨me

### 1. ProblÃ¨mes linÃ©aires (linear_classification, and_gate, or_gate)
```
Architecture :
- Input size : 2
- Layer 1 : 1 neuron, sigmoid

EntraÃ®nement :
- Learning rate : 0.1
- Epochs : 100
```

### 2. ProblÃ¨mes non-linÃ©aires simples (moons, circles)
```
Architecture :
- Input size : 2
- Layer 1 : 4-8 neurons, relu
- Layer 2 : 1 neuron, sigmoid

EntraÃ®nement :
- Learning rate : 0.01
- Epochs : 200-500
```

### 3. ProblÃ¨mes complexes (spiral, complex_classification)
```
Architecture :
- Input size : 2 ou 5 (selon le dataset)
- Layer 1 : 16-32 neurons, relu
- Layer 2 : 8-16 neurons, relu
- Layer 3 : 1 neuron, sigmoid

EntraÃ®nement :
- Learning rate : 0.001
- Epochs : 500-1000
```

### 4. Multi-classes (multiclass, blobs)
```
Architecture :
- Input size : 2 ou 3
- Layer 1 : 8-16 neurons, relu
- Layer 2 : nombre de classes, sigmoid

EntraÃ®nement :
- Learning rate : 0.01
- Epochs : 200-500
```

### 5. RÃ©gression
```
Architecture :
- Input size : 1 ou 2
- Layer 1 : 8-16 neurons, relu
- Layer 2 : 1 neuron, linear

EntraÃ®nement :
- Learning rate : 0.001
- Epochs : 500-1000
```

## ðŸ“ Ã‰tapes complÃ¨tes pour tester

1. **Charger les donnÃ©es** :
   - Onglet "Training" â†’ "Load CSV"
   - Le systÃ¨me divise automatiquement en 80% train / 20% test

2. **Construire le rÃ©seau** :
   - Onglet "Architecture"
   - DÃ©finir "Input Size" selon le dataset
   - Ajouter les couches une par une
   - Cliquer "Build Network"

3. **EntraÃ®ner** :
   - Onglet "Training"
   - Configurer les hyperparamÃ¨tres
   - Cliquer "Start Training"
   - Observer la progression dans le log

4. **Tester** :
   - Onglet "Testing"
   - Cliquer "Test on Dataset" pour Ã©valuer sur les donnÃ©es de test
   - Ou entrer des valeurs manuelles dans "Test Input"

5. **Visualiser** :
   - Onglet "Visualization"
   - "Plot Architecture" : voir la structure du rÃ©seau
   - "Plot Training History" : voir l'Ã©volution de l'entraÃ®nement
   - "Plot Decision Boundary" : voir les frontiÃ¨res de dÃ©cision (2D seulement)

## ðŸ’¡ Conseils

- Commencez avec des problÃ¨mes simples (linear, and_gate)
- Augmentez progressivement la complexitÃ©
- Si l'accuracy stagne, essayez :
  - D'ajouter plus de neurones/couches
  - De changer la fonction d'activation
  - D'ajuster le learning rate
  - D'augmenter les epochs

## ðŸŽ¯ Objectifs d'accuracy typiques

- ProblÃ¨mes linÃ©aires : > 95%
- Moons/Circles : > 90%
- Spiral : > 85%
- Multi-classes : > 80%
- RÃ©gression : Loss < 0.1

Bon apprentissage ! ðŸš€